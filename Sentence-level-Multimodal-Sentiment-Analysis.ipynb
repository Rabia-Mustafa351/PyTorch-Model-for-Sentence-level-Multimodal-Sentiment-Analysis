{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2718c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.8.1\n",
      "    Uninstalling huggingface-hub-0.8.1:\n",
      "      Successfully uninstalled huggingface-hub-0.8.1\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ebb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ab5af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>39194</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>39195</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>39196</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>39197</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>39198</td>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39199 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid  split                       filename  successful  \\\n",
       "0               0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1               1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2               2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3               3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4               4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...           ...    ...    ...                            ...         ...   \n",
       "39194       39194  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39195       39195  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39196       39196  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39197       39197  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39198       39198  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[39199 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('C:/Users/USER/Downloads/sentiment/sentiment.csv')\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6deb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39199"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcebefa",
   "metadata": {},
   "source": [
    "# Resizing Images and storing in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad1f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions=data[['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4971fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path of the directory containing the images to be resized\n",
    "input_dir = 'C:/Users/USER/Downloads/sentiment/sentiment_images'\n",
    "\n",
    "# Path of the directory to save the resized images\n",
    "output_dir = 'C:/Users/USER/Downloads/sentiment/resized_images'\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through all the files in the input directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    # Open the image file\n",
    "    with Image.open(os.path.join(input_dir, file_name)) as img:\n",
    "        # Resize the image to 224x224 pixels\n",
    "        img = img.resize((224, 224))\n",
    "        # Save the resized image to the output directory\n",
    "        img.save(os.path.join(output_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7f932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras_applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow.keras.applications.resnet50 as resnet50\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# from tensorflow.keras.applications import ResNet50, ResNet101\n",
    "# from tensorflow.keras.layers import Input, AveragePooling2D, Flatten, Dense\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Load the ResNet-50 model\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 1))\n",
    "\n",
    "# # Remove the last layer of the model\n",
    "# x = base_model.output\n",
    "# x = AveragePooling2D()(x)\n",
    "# x = Flatten()(x)\n",
    "# output = Dense(1000, activation='softmax')(x)\n",
    "\n",
    "# # Define a new model with fewer layers\n",
    "# model = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf48c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path of the input image file\n",
    "input_file = 'C:/Users/USER/Downloads/sentiment/sentiment_images/COCO_val2014_000000000136.jpg'\n",
    "\n",
    "# Load the input image and preprocess it\n",
    "img = image.load_img(input_file, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = resnet50.preprocess_input(x)\n",
    "\n",
    "# Use the model to extract visual features from the input image\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf9a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text features =>word embedding \n",
    "# caption image name ...text feature ....image feature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463398c3",
   "metadata": {},
   "source": [
    "# Extracting Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d4d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf1858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = 'C:/Users/USER/Downloads/sentiment/sentiment_images'\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2acea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations to resize and normalize images:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83ca3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "867c2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset for loading images\n",
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_list = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.folder_path, self.image_list[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert image to RGB mode\n",
    "        img_tensor = self.transform(img)\n",
    "        return img_tensor, self.image_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5309241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create custom dataset and data loader\n",
    "dataset = ImageFolderDataset(img_folder, transform)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Extract features from images and save in DataFrame\n",
    "features = []\n",
    "img_names = []\n",
    "with torch.no_grad():\n",
    "    for i, (images, names) in enumerate(data_loader):\n",
    "        outputs = model(images)\n",
    "        features.append(outputs.cpu().numpy())\n",
    "        img_names.extend(names)\n",
    "    features = np.concatenate(features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f6c71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.9941082 , -1.6384274 , -3.1486473 , ..., -0.9868657 ,\n",
       "        -1.0032473 , -0.7259805 ],\n",
       "       [-5.177543  , -0.63080305, -3.8554313 , ..., -1.7471942 ,\n",
       "         0.2654792 , -0.55904245],\n",
       "       [-0.81202096, -1.1953924 , -2.6149926 , ..., -3.2282257 ,\n",
       "         1.6661296 ,  0.8019966 ],\n",
       "       ...,\n",
       "       [-2.7505112 , -2.8570902 , -1.2040228 , ..., -4.441653  ,\n",
       "         0.5440762 ,  1.8396794 ],\n",
       "       [-3.1989555 , -3.7491665 , -1.847029  , ..., -0.6018707 ,\n",
       "        -1.057193  , -1.0331337 ],\n",
       "       [-5.4347568 , -2.5267184 , -2.243201  , ..., -2.9584827 ,\n",
       "         0.3885254 ,  4.8186126 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4531f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-3.994108200073242, -1.6384273767471313, -3.1...</td>\n",
       "      <td>COCO_val2014_000000000136.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-5.1775431632995605, -0.6308030486106873, -3....</td>\n",
       "      <td>COCO_val2014_000000000139.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.8120209574699402, -1.195392370223999, -2.6...</td>\n",
       "      <td>COCO_val2014_000000001503.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1.056734561920166, -1.7733153104782104, -1.0...</td>\n",
       "      <td>COCO_val2014_000000002179.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1.0756490230560303, -4.661337852478027, -3.0...</td>\n",
       "      <td>COCO_val2014_000000002315.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>[-4.936171054840088, -0.593064546585083, -2.83...</td>\n",
       "      <td>COCO_val2014_000000578130.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>[2.2506892681121826, 1.165312647819519, 1.0888...</td>\n",
       "      <td>COCO_val2014_000000578427.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>[-2.7505111694335938, -2.8570902347564697, -1....</td>\n",
       "      <td>COCO_val2014_000000578553.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>[-3.198955535888672, -3.749166488647461, -1.84...</td>\n",
       "      <td>COCO_val2014_000000578703.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>[-5.434756755828857, -2.5267183780670166, -2.2...</td>\n",
       "      <td>COCO_val2014_000000580027.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2221 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               features  \\\n",
       "0     [-3.994108200073242, -1.6384273767471313, -3.1...   \n",
       "1     [-5.1775431632995605, -0.6308030486106873, -3....   \n",
       "2     [-0.8120209574699402, -1.195392370223999, -2.6...   \n",
       "3     [-1.056734561920166, -1.7733153104782104, -1.0...   \n",
       "4     [-1.0756490230560303, -4.661337852478027, -3.0...   \n",
       "...                                                 ...   \n",
       "2216  [-4.936171054840088, -0.593064546585083, -2.83...   \n",
       "2217  [2.2506892681121826, 1.165312647819519, 1.0888...   \n",
       "2218  [-2.7505111694335938, -2.8570902347564697, -1....   \n",
       "2219  [-3.198955535888672, -3.749166488647461, -1.84...   \n",
       "2220  [-5.434756755828857, -2.5267183780670166, -2.2...   \n",
       "\n",
       "                             images  \n",
       "0     COCO_val2014_000000000136.jpg  \n",
       "1     COCO_val2014_000000000139.jpg  \n",
       "2     COCO_val2014_000000001503.jpg  \n",
       "3     COCO_val2014_000000002179.jpg  \n",
       "4     COCO_val2014_000000002315.jpg  \n",
       "...                             ...  \n",
       "2216  COCO_val2014_000000578130.jpg  \n",
       "2217  COCO_val2014_000000578427.jpg  \n",
       "2218  COCO_val2014_000000578553.jpg  \n",
       "2219  COCO_val2014_000000578703.jpg  \n",
       "2220  COCO_val2014_000000580027.jpg  \n",
       "\n",
       "[2221 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Given array\n",
    "array = np.array(features)\n",
    "\n",
    "# Create DataFrame with a single column 'features'\n",
    "df2 = pd.DataFrame({'features': array.tolist()})\n",
    "df2['images']=img_names\n",
    "# Print the DataFrame\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2895fba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "      <th>features</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39104</th>\n",
       "      <td>39140</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'standing', 'amongst', 'tall'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a giraffe standing amongst tall dry grass unde...</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39105</th>\n",
       "      <td>39141</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'walking', 'through', 'a', 'f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A giraffe walking through a field of dead grass.</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39106</th>\n",
       "      <td>39142</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'lone', 'giraffe', 'walking', 'in', 'dry...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A lone giraffe walking in dry vegetation in fr...</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39107</th>\n",
       "      <td>39143</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'standing', 'amongst', 'tall'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a giraffe standing amongst tall dry grass unde...</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39108</th>\n",
       "      <td>39144</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'walking', 'through', 'a', 'f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A giraffe walking through a field of dead grass.</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39109 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid  split                       filename  successful  \\\n",
       "0               0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1               1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2               2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3               3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4               4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...           ...    ...    ...                            ...         ...   \n",
       "39104       39140  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39105       39141  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39106       39142  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39107       39143  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39108       39144  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39104  ['a', 'giraffe', 'standing', 'amongst', 'tall'...   \n",
       "39105  ['a', 'giraffe', 'walking', 'through', 'a', 'f...   \n",
       "39106  ['a', 'lone', 'giraffe', 'walking', 'in', 'dry...   \n",
       "39107  ['a', 'giraffe', 'standing', 'amongst', 'tall'...   \n",
       "39108  ['a', 'giraffe', 'walking', 'through', 'a', 'f...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39104  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39105          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]          0   \n",
       "39106  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39107  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39108          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]          0   \n",
       "\n",
       "                                                     raw  \\\n",
       "0      a plate of delicious food including French fries.   \n",
       "1      French fries are not a healthy food but it is ...   \n",
       "2      The plate has one of my favorite foods on it, ...   \n",
       "3             It was disgusting food, not just bad food.   \n",
       "4           A plate of disgusting food found at a diner.   \n",
       "...                                                  ...   \n",
       "39104  a giraffe standing amongst tall dry grass unde...   \n",
       "39105   A giraffe walking through a field of dead grass.   \n",
       "39106  A lone giraffe walking in dry vegetation in fr...   \n",
       "39107  a giraffe standing amongst tall dry grass unde...   \n",
       "39108   A giraffe walking through a field of dead grass.   \n",
       "\n",
       "                                                features  \\\n",
       "0      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "1      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "2      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "3      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "4      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "...                                                  ...   \n",
       "39104  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39105  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39106  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39107  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39108  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "\n",
       "                              images  \n",
       "0      COCO_val2014_000000389081.jpg  \n",
       "1      COCO_val2014_000000389081.jpg  \n",
       "2      COCO_val2014_000000389081.jpg  \n",
       "3      COCO_val2014_000000389081.jpg  \n",
       "4      COCO_val2014_000000389081.jpg  \n",
       "...                              ...  \n",
       "39104  COCO_val2014_000000487236.jpg  \n",
       "39105  COCO_val2014_000000487236.jpg  \n",
       "39106  COCO_val2014_000000487236.jpg  \n",
       "39107  COCO_val2014_000000487236.jpg  \n",
       "39108  COCO_val2014_000000487236.jpg  \n",
       "\n",
       "[39109 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = data.merge(df2, left_on=\"filename\", right_on=\"images\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a75cea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=merged_df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54aa8a4",
   "metadata": {},
   "source": [
    "# TEXT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d60870b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define a function to apply encoding using the tokenizer\n",
    "def encode_tokens(tokens):\n",
    "    return tokenizer.encode(tokens, padding=True, truncation=True)\n",
    "\n",
    "# Apply encoding to the 'tokens' column\n",
    "merged_df['encoded_tokens'] = merged_df['tokens'].apply(encode_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "126dee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "      <th>features</th>\n",
       "      <th>images</th>\n",
       "      <th>encoded_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>[101, 1031, 1005, 2413, 1005, 1010, 1005, 2220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1996, 1005, 1010, 1005, 5127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>[101, 1031, 1005, 2009, 1005, 1010, 1005, 2001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39104</th>\n",
       "      <td>39140</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'standing', 'amongst', 'tall'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a giraffe standing amongst tall dry grass unde...</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39105</th>\n",
       "      <td>39141</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'walking', 'through', 'a', 'f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A giraffe walking through a field of dead grass.</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39106</th>\n",
       "      <td>39142</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'lone', 'giraffe', 'walking', 'in', 'dry...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A lone giraffe walking in dry vegetation in fr...</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 1045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39107</th>\n",
       "      <td>39143</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'standing', 'amongst', 'tall'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a giraffe standing amongst tall dry grass unde...</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39108</th>\n",
       "      <td>39144</td>\n",
       "      <td>12458</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'giraffe', 'walking', 'through', 'a', 'f...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A giraffe walking through a field of dead grass.</td>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>COCO_val2014_000000487236.jpg</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39109 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  imgid  split                       filename  successful  \\\n",
       "0               0  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1               1  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2               2  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3               3  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4               4  31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...           ...    ...    ...                            ...         ...   \n",
       "39104       39140  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39105       39141  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39106       39142  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39107       39143  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "39108       39144  12458   test  COCO_val2014_000000487236.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39104  ['a', 'giraffe', 'standing', 'amongst', 'tall'...   \n",
       "39105  ['a', 'giraffe', 'walking', 'through', 'a', 'f...   \n",
       "39106  ['a', 'lone', 'giraffe', 'walking', 'in', 'dry...   \n",
       "39107  ['a', 'giraffe', 'standing', 'amongst', 'tall'...   \n",
       "39108  ['a', 'giraffe', 'walking', 'through', 'a', 'f...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39104  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39105          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]          0   \n",
       "39106  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39107  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39108          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1]          0   \n",
       "\n",
       "                                                     raw  \\\n",
       "0      a plate of delicious food including French fries.   \n",
       "1      French fries are not a healthy food but it is ...   \n",
       "2      The plate has one of my favorite foods on it, ...   \n",
       "3             It was disgusting food, not just bad food.   \n",
       "4           A plate of disgusting food found at a diner.   \n",
       "...                                                  ...   \n",
       "39104  a giraffe standing amongst tall dry grass unde...   \n",
       "39105   A giraffe walking through a field of dead grass.   \n",
       "39106  A lone giraffe walking in dry vegetation in fr...   \n",
       "39107  a giraffe standing amongst tall dry grass unde...   \n",
       "39108   A giraffe walking through a field of dead grass.   \n",
       "\n",
       "                                                features  \\\n",
       "0      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "1      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "2      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "3      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "4      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "...                                                  ...   \n",
       "39104  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39105  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39106  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39107  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39108  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "\n",
       "                              images  \\\n",
       "0      COCO_val2014_000000389081.jpg   \n",
       "1      COCO_val2014_000000389081.jpg   \n",
       "2      COCO_val2014_000000389081.jpg   \n",
       "3      COCO_val2014_000000389081.jpg   \n",
       "4      COCO_val2014_000000389081.jpg   \n",
       "...                              ...   \n",
       "39104  COCO_val2014_000000487236.jpg   \n",
       "39105  COCO_val2014_000000487236.jpg   \n",
       "39106  COCO_val2014_000000487236.jpg   \n",
       "39107  COCO_val2014_000000487236.jpg   \n",
       "39108  COCO_val2014_000000487236.jpg   \n",
       "\n",
       "                                          encoded_tokens  \n",
       "0      [101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...  \n",
       "1      [101, 1031, 1005, 2413, 1005, 1010, 1005, 2220...  \n",
       "2      [101, 1031, 1005, 1996, 1005, 1010, 1005, 5127...  \n",
       "3      [101, 1031, 1005, 2009, 1005, 1010, 1005, 2001...  \n",
       "4      [101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...  \n",
       "...                                                  ...  \n",
       "39104  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...  \n",
       "39105  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...  \n",
       "39106  [101, 1031, 1005, 1037, 1005, 1010, 1005, 1045...  \n",
       "39107  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...  \n",
       "39108  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...  \n",
       "\n",
       "[39109 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ea2e3",
   "metadata": {},
   "source": [
    "# Selecting ROws for tarin test slpit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2596878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>encoded_tokens</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>[101, 1031, 1005, 2413, 1005, 1010, 1005, 2220...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>[101, 1031, 1005, 1996, 1005, 1010, 1005, 5127...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>[101, 1031, 1005, 2009, 1005, 1010, 1005, 2001...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.8987646102905273, -1.04927659034729, -0.630...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39104</th>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39105</th>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39106</th>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 1045...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39107</th>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39108</th>\n",
       "      <td>[-1.8074800968170166, -2.944333076477051, -1.0...</td>\n",
       "      <td>[101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                features  \\\n",
       "0      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "1      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "2      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "3      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "4      [2.8987646102905273, -1.04927659034729, -0.630...   \n",
       "...                                                  ...   \n",
       "39104  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39105  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39106  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39107  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "39108  [-1.8074800968170166, -2.944333076477051, -1.0...   \n",
       "\n",
       "                                          encoded_tokens  sentiment  \n",
       "0      [101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...          1  \n",
       "1      [101, 1031, 1005, 2413, 1005, 1010, 1005, 2220...          1  \n",
       "2      [101, 1031, 1005, 1996, 1005, 1010, 1005, 5127...          1  \n",
       "3      [101, 1031, 1005, 2009, 1005, 1010, 1005, 2001...          0  \n",
       "4      [101, 1031, 1005, 1037, 1005, 1010, 1005, 5127...          0  \n",
       "...                                                  ...        ...  \n",
       "39104  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...          0  \n",
       "39105  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...          0  \n",
       "39106  [101, 1031, 1005, 1037, 1005, 1010, 1005, 1045...          0  \n",
       "39107  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...          0  \n",
       "39108  [101, 1031, 1005, 1037, 1005, 1010, 1005, 2102...          0  \n",
       "\n",
       "[39109 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainTestData = merged_df[['features', 'encoded_tokens','sentiment']]\n",
    "TrainTestData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3d6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(merged_df['image_name'])\n",
    "# del(merged_df['imgid'])\n",
    "# del(merged_df['imgid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62ee7d",
   "metadata": {},
   "source": [
    "# Padding tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf14bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_24444/295159460.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TrainTestData['encoded_tokens'] = padded_tokens\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named 'TrainTestData' and the column of encoded tokens is 'encoded_tokens'\n",
    "encoded_tokens = TrainTestData['encoded_tokens']\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max(len(tokens) for tokens in encoded_tokens)\n",
    "\n",
    "# Initialize a new list to store the padded sequences\n",
    "padded_tokens = []\n",
    "\n",
    "# Pad the sequences with zeros\n",
    "for tokens in encoded_tokens:\n",
    "    padded_tokens.append(tokens + [0] * (max_len - len(tokens)))\n",
    "\n",
    "# Convert the padded tokens to a NumPy array\n",
    "padded_tokens = np.array(padded_tokens)\n",
    "\n",
    "# Update the 'encoded_tokens' column in the DataFrame\n",
    "TrainTestData['encoded_tokens'] = padded_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd3cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e91e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c699bf1",
   "metadata": {},
   "source": [
    "# SPLITTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "732178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset =TrainTestData\n",
    "# Separate features and labels\n",
    "features = dataset.iloc[:, 1:1000].values\n",
    "labels = dataset['sentiment'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(TrainTestData, dataset['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ce27f",
   "metadata": {},
   "source": [
    "# MultimodalSentimentAnalysisModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4022e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Preprocessing dataset\n",
    "features = TrainTestData['features'].tolist()\n",
    "encoded_tokens = TrainTestData['encoded_tokens'].tolist()\n",
    "sentiment = TrainTestData['sentiment'].tolist()\n",
    "df=TrainTestData\n",
    "# Step 2: Split your dataset into training, validation, and test sets\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(features, sentiment, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5c7cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Create an instance of MultimodalSentimentAnalysisModel\n",
    "class MultimodalSentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, textual_input_size, visual_input_size, hidden_size, num_classes):\n",
    "        super(MultimodalSentimentAnalysisModel, self).__init__()\n",
    "\n",
    "        self.textual_input_size = textual_input_size\n",
    "        self.visual_input_size = visual_input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Textual input processing layers\n",
    "        self.textual_layers = nn.Sequential(\n",
    "            nn.Linear(textual_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Visual input processing layers\n",
    "        self.visual_layers = nn.Sequential(\n",
    "            nn.Linear(visual_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fusion layer to combine textual and visual features\n",
    "        self.fusion_layer = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, textual_input, visual_input):\n",
    "        textual_features = self.textual_layers(textual_input)\n",
    "        visual_features = self.visual_layers(visual_input)\n",
    "\n",
    "        combined_features = torch.cat((textual_features, visual_features), dim=1)\n",
    "        fused_features = self.fusion_layer(combined_features)\n",
    "\n",
    "        output = self.output_layer(fused_features)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Define the input sizes, hidden size, and number of classes\n",
    "textual_input_size = len(encoded_tokens)\n",
    "visual_input_size = len(features)\n",
    "hidden_size = 256\n",
    "num_classes = 2  # Assuming binary sentiment classification\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MultimodalSentimentAnalysisModel(textual_input_size, visual_input_size, hidden_size, num_classes)\n",
    "\n",
    "# Step 4: Converting input features and target variables to tensors\n",
    "textual_input_train = torch.FloatTensor(X_train)\n",
    "visual_input_train = torch.FloatTensor(y_train)\n",
    "target_train = torch.LongTensor(y_train)\n",
    "\n",
    "textual_input_val = torch.FloatTensor(X_val)\n",
    "visual_input_val = torch.FloatTensor(y_val)\n",
    "target_val = torch.LongTensor(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "131df7b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0\n",
      "epochs 1\n",
      "epochs 2\n",
      "epochs 3\n",
      "epochs 4\n",
      "epochs 5\n",
      "epochs 6\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 6: Train the model\n",
    "num_epochs = 7\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(\"epochs\",epoch)     \n",
    "    for i in range(0, len(textual_input_train), batch_size):\n",
    "        # Prepare batch data\n",
    "        textual_batch = textual_input_train[i:i+batch_size]\n",
    "        visual_batch = visual_input_train[i:i+batch_size]\n",
    "        target_batch = target_train[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(textual_batch, visual_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4616d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 60\n",
      " Precision: 70\n",
      " F1 Score: 58.333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model\n",
    "model.eval()\n",
    "\n",
    "# Forward pass on validation set\n",
    "with torch.no_grad():\n",
    "    val_output = model(textual_input_val, visual_input_val)\n",
    "    val_predictions = torch.argmax(val_output, dim=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "val_accuracy = torch.sum(val_predictions == target_val).item() / len(target_val)\n",
    "print(f\" Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Calculate precision and F1 score\n",
    "TP = torch.sum((val_predictions == 1) & (target_val == 1)).item()\n",
    "FP = torch.sum((val_predictions == 1) & (target_val == 0)).item()\n",
    "FN = torch.sum((val_predictions == 0) & (target_val == 1)).item()\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\" Precision: {precision}\")\n",
    "print(f\" F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a562f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3f6ec285",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=TrainTestData['encoded_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4da54b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2825e2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a519d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e404d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b324dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bb342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
